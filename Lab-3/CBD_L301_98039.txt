
Run cassandra with docker:
https://cassandra.apache.org/_/quickstart.html

docker run --name cassandra cassandra -p 9042:9042



sudo service cassandra start
sudo service cassandra status

---

http://cassandra.apache.org/doc/latest/cassandra/cql/index.html

--- Inserting and Querying

The API for Cassandra is CQL, the Cassandra Query Language. 
To use CQL, you will need to connect to the cluster, using either:

- cqlsh, a shell for CQL
- A client driver for Cassandra
- Apache Zeppelin, a notebook-style tool

cqlsh is a command-line shell for interacting with Cassandra using CQL. 
It connects to the single node specified on the command line.

$ bin/cqlsh localhost

--- CQL (Cassandra Query Language)

CQL stores data in tables, whose schema defines the layout of the data in the table. Tables are located in keyspaces. 
A keyspace defines options that apply to all the keyspace’s tables. A good general rule is one keyspace per application. 


The names of the keyspaces and tables are defined by the following grammar:

keyspace_name::= name
table_name::= [keyspace_name '.' ] name
name::= unquoted_name | quoted_name
unquoted_name::= re('[a-zA-Z_0-9]\{1, 48}')
quoted_name::= '"' unquoted_name '"'

By default, keyspace and table names are case-insensitive (myTable is equivalent to mytable).
However, case sensitivity can be forced by using double-quotes ("myTable" is different from mytable).

--- Create keyspace

create_keyspace_statement::= CREATE KEYSPACE [ IF NOT EXISTS ] keyspace_name
	WITH options

(Example)
CREATE KEYSPACE excelsior
   WITH replication = {'class': 'SimpleStrategy', 'replication_factor' : 3};

Attempting to create a keyspace that already exists will return an error unless the IF NOT EXISTS option is used.

The supported options are:

- Replication: The replication strategy and options to use for the keyspace (see details below).
- Durable_writes: Whether to use the commit log for updates on this keyspace (disable this option at your own risk!).

--- Replication (class)

- Simple strategy
A simple strategy that defines a replication factor for data to be spread across the entire cluster.
This is generally not a wise choice for production, as it does not respect datacenter layouts and can lead to wildly varying query latency. 
For production, use NetworkTopologyStrategy. 

SimpleStrategy supports a single mandatory argument: Replication_factor, the number of replicas to store per range

- NetworkTopologyStrategy

A production-ready replication strategy that sets the replication factor independently for each data-center. 
The rest of the sub-options are key-value pairs, with a key set to a data-center name and its value set to the associated replication factor.

When later altering keyspaces and changing the replication_factor, auto-expansion will only add new datacenters for safety, it will not alter existing datacenters or remove any, even if they are no longer in the cluster.
If you want to remove datacenters while setting the replication_factor, explicitly zero out the datacenter you want to have zero replicas.

CREATE KEYSPACE excalibur
    WITH replication = {'class': 'NetworkTopologyStrategy', 'replication_factor' : 3};

DESCRIBE KEYSPACE excalibur;

will result in:

CREATE KEYSPACE excalibur WITH replication = {'class': 'NetworkTopologyStrategy', 'DC1': '3', 'DC2': '3'} AND durable_writes = true;

---

The USE statement changes the current keyspace to the specified keyspaces.
A number of objects in CQL are bound to a keyspace and the current keyspace is the default keyspace used when those objects are referred to in a query without a fully-qualified name (without a prefixed keyspace name). 
A USE statement specifies the keyspace to use as an argument:

use_statement::= USE keyspace_name

--- Alter keyspace

alter_keyspace_statement::= ALTER KEYSPACE keyspace_name
	WITH options

--- Drop keyspace

drop_keyspace_statement::= DROP KEYSPACE [ IF EXISTS ] keyspace_name

--- Create table

create_table_statement::= CREATE TABLE [ IF NOT EXISTS ] table_name '('
	column_definition  ( ',' column_definition )*
	[ ',' PRIMARY KEY '(' primary_key ')' ]
	 ')' [ WITH table_options ]

column_definition::= column_name cql_type [ STATIC ] [ PRIMARY KEY]

primary_key::= partition_key [ ',' clustering_columns ]

partition_key::= column_name  | '(' column_name ( ',' column_name )* ')'

clustering_columns::= column_name ( ',' column_name )*

table_options:=: COMPACT STORAGE [ AND table_options ]
	| CLUSTERING ORDER BY '(' clustering_order ')'
	[ AND table_options ]  | options

clustering_order::= column_name (ASC | DESC) ( ',' column_name (ASC | DESC) )*

CREATE TABLE monkey_species (
    species text PRIMARY KEY,
    common_name text,
    population varint,
    average_size int
) WITH comment='Important biological records';

---  Static column

Some columns can be declared as STATIC in a table definition. 
A column that is static will be “shared” by all the rows belonging to the same partition (having the same partition key).

--- Primary key 

Within a table, a row is uniquely identified by its PRIMARY KEY, and hence all tables must define a single PRIMARY KEY.
A PRIMARY KEY is composed of one or more of the defined columns in the table.

Partition key:
It is the first component of the primary key definition. It can be a single column or, using an additional set of parenthesis, can be multiple columns.
A table must have at least one partition key, the smallest possible table definition is: CREATE TABLE t (k text PRIMARY KEY);

Clustering columns:
The columns are the columns that follow the partition key in the primary key definition. The order of those columns define the clustering order.

PRIMARY KEY (a): a is the single partition key and there are no clustering columns
PRIMARY KEY (a, b, c) : a is the single partition key and b and c are the clustering columns
PRIMARY KEY ((a, b), c) : a and b compose the composite partition key and c is the clustering column

-- Partion key

Within a table, CQL defines the notion of a partition that defines the location of data within a Cassandra cluster.
A partition is the set of rows that share the same value for their partition key.

Note that if the partition key is composed of multiple columns, then rows belong to the same partition when they have the same values for all those partition key columns. 

---

CREATE KEYSPACE videoP3 WITH REPLICATION = {}

use videoP3;

CREATE TABLE users {
    username varchar, 
    firstname varchar, 
    lastname varchar, 
    PRIMARY KEY (username)
}

insert into users(username, firstname, lastname) values ('danny', 'Daniela', 'Dias');

select * from users;


--- 3.3 Cassandra Driver

https://docs.datastax.com/en/developer/java-driver/3.0/manual/

Cluster cluster = null;
try {
    cluster = Cluster.builder()                                                    // (1)
            .addContactPoint("127.0.0.1")
            .build();
    Session session = cluster.connect();                                           // (2)

    ResultSet rs = session.execute("select release_version from system.local");    // (3)
    Row row = rs.one();
    System.out.println(row.getString("release_version"));                          // (4)
} finally {
    if (cluster != null) cluster.close();                                          // (5)
}

(1) The Cluster object is the main entry point of the driver. 
It holds the known state of the actual Cassandra cluster (notably the Metadata). 
This class is thread-safe, you should create a single instance (per target Cassandra cluster), and share it throughout your application;

(2) The Session is what you use to execute queries. Likewise, it is thread-safe and should be reused;

(3) We use execute to send a query to Cassandra. This returns a ResultSet, which is essentially a collection of Row objects.
On the next line, we extract the first row (which is the only one in this case);

(4) We extract the value of the first (and only) column from the row;

(5) Finally, we close the cluster after we’re done with it.
This will also close any session that was created from this cluster.
This step is important because it frees underlying resources (TCP connections, thread pools…).
In a real application, you would typically do this at shutdown (for example, when undeploying your webapp).

---

Cluster initialization

The initialization sequence is the following:

- Initialize internal state (thread pools, utility components, etc.);

- Try to connect to each of the contact points in sequence. 
The order is not deterministic (in fact, the driver shuffles the list to avoid hotspots if a large number of clients share the same contact points). 
If no contact point replies, a NoHostAvailableException is thrown and the process stops here;

- Otherwise, the successful contact point is elected as the control host. 
The driver negotiates the native protocol version with it, and queries its system tables to discover the addresses of the other hosts.